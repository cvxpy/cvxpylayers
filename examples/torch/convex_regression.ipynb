{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Regression: Learning Convex Functions from Data\n",
    "\n",
    "This notebook demonstrates **convex regression** — learning a convex function that best fits scattered data, using CVXPYlayers to enforce convexity constraints.\n",
    "\n",
    "**Model**: We represent the convex function as a max-of-affines:\n",
    "\n",
    "$$f_\\theta(x) = \\max_j \\; (a_j x + b_j)$$\n",
    "\n",
    "where $\\theta = \\{a_j, b_j\\}_{j=1}^K$ are learnable PyTorch parameters. Since the pointwise max of affine functions is always convex, this model is *convex by construction*.\n",
    "\n",
    "**Approach**: We evaluate $f_\\theta$ directly in PyTorch (using `torch.max`), and use a CvxpyLayer to solve a **convex projection** problem — projecting noisy data onto the epigraph of $f_\\theta$ to get denoised predictions.\n",
    "\n",
    "**Training**: Learn $\\theta$ via SGD to minimize prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from cvxpylayers.torch import CvxpyLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data from a Convex Function\n",
    "\n",
    "We sample data from a known convex function $g(x) = x^2/4 + |x|$ with added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "n_data = 150\n",
    "\n",
    "X_np = np.random.uniform(-3, 3, size=(n_data, 1))\n",
    "\n",
    "def true_convex(x):\n",
    "    return 0.25 * x[:, 0] ** 2 + np.abs(x[:, 0])\n",
    "\n",
    "Y_np = true_convex(X_np) + 0.3 * np.random.randn(n_data)\n",
    "\n",
    "X_data = torch.tensor(X_np, dtype=torch.float64)\n",
    "Y_data = torch.tensor(Y_np, dtype=torch.float64)\n",
    "\n",
    "print(f\"{n_data} data points generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-of-Affines Evaluation (PyTorch)\n",
    "\n",
    "The function $f_\\theta(x) = \\max_j (a_j x + b_j)$ is differentiable almost everywhere and can be computed directly in PyTorch. The slopes $a_j$ and intercepts $b_j$ are learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 8  # number of affine pieces\n",
    "\n",
    "# Learnable parameters\n",
    "a_tch = nn.Parameter(torch.randn(K, 1, dtype=torch.float64) * 0.5)\n",
    "b_tch = nn.Parameter(torch.randn(K, dtype=torch.float64) * 0.5)\n",
    "\n",
    "def max_of_affines(x, a, b):\n",
    "    \"\"\"Evaluate f(x) = max_j (a_j^T x + b_j) for a batch of x.\n",
    "    \n",
    "    Args:\n",
    "        x: (batch, input_dim)\n",
    "        a: (K, input_dim) slopes\n",
    "        b: (K,) intercepts\n",
    "    Returns:\n",
    "        (batch,) function values\n",
    "    \"\"\"\n",
    "    # (batch, K) = (batch, input_dim) @ (input_dim, K) + (K,)\n",
    "    vals = x @ a.T + b.unsqueeze(0)\n",
    "    return vals.max(dim=1).values\n",
    "\n",
    "print(f\"Max-of-{K}-affines model with {2*K} parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CvxpyLayer: Convex Projection\n",
    "\n",
    "Given a noisy observation $y$ and a convex function $f_\\theta$, we can *project* $y$ onto the epigraph of $f_\\theta$ at point $x$ by solving:\n",
    "\n",
    "$$\\min_z \\; (z - y)^2 \\quad \\text{s.t.} \\; z \\geq c$$\n",
    "\n",
    "where $c$ is the convex function value $f_\\theta(x)$. This is a parametric QP with parameter $c$ (the function value) and $y$ (the target). The CvxpyLayer allows gradients to flow back through this projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cp.Variable(name=\"z\")\n",
    "c_param = cp.Parameter(name=\"lower_bound\")\n",
    "y_param = cp.Parameter(name=\"target\")\n",
    "\n",
    "# Project y onto [c, inf) — closest point to y that's >= c\n",
    "objective = cp.Minimize(cp.square(z - y_param))\n",
    "constraints = [z >= c_param]\n",
    "proj_problem = cp.Problem(objective, constraints)\n",
    "assert proj_problem.is_dpp()\n",
    "\n",
    "proj_layer = CvxpyLayer(proj_problem, parameters=[c_param, y_param], variables=[z])\n",
    "print(\"Projection layer created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "We train the max-of-affines parameters to minimize MSE. The CvxpyLayer projection clips predictions to be at least as large as the convex function value, acting as a convexity-aware regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([a_tch, b_tch], lr=0.05)\n",
    "losses = []\n",
    "\n",
    "n_epochs = 300\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    idx = torch.randperm(n_data)[:batch_size]\n",
    "    X_batch = X_data[idx]\n",
    "    Y_batch = Y_data[idx]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Evaluate max-of-affines\n",
    "    f_vals = max_of_affines(X_batch, a_tch, b_tch)\n",
    "    \n",
    "    # Project targets through CvxpyLayer\n",
    "    projected = []\n",
    "    for i in range(batch_size):\n",
    "        (z_val,) = proj_layer(f_vals[i], Y_batch[i])\n",
    "        projected.append(z_val)\n",
    "    projected = torch.stack(projected).squeeze()\n",
    "    \n",
    "    loss = torch.mean((projected - Y_batch) ** 2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 75 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Learned Convex Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on a dense grid\n",
    "x_grid = torch.linspace(-3.5, 3.5, 200, dtype=torch.float64).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_learned = max_of_affines(x_grid, a_tch, b_tch).numpy()\n",
    "\n",
    "y_true = true_convex(x_grid.numpy())\n",
    "\n",
    "# Individual affine pieces\n",
    "a_np = a_tch.detach().numpy()\n",
    "b_np = b_tch.detach().numpy()\n",
    "x_plot = x_grid.numpy().flatten()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: fit vs true\n",
    "ax1.scatter(X_np, Y_np, alpha=0.3, s=15, c='gray', label='Data')\n",
    "ax1.plot(x_plot, y_true, 'b--', linewidth=2, label='True function')\n",
    "ax1.plot(x_plot, y_learned, 'r-', linewidth=2, label='Learned (max-of-affines)')\n",
    "for j in range(K):\n",
    "    y_affine = a_np[j, 0] * x_plot + b_np[j]\n",
    "    ax1.plot(x_plot, y_affine, '--', alpha=0.2, color='orange', linewidth=0.8)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Convex Regression Fit')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(-1, 7)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: training loss\n",
    "ax2.plot(losses, 'g-', alpha=0.7)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE Loss')\n",
    "ax2.set_title('Training Loss')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation on all data\n",
    "with torch.no_grad():\n",
    "    f_all = max_of_affines(X_data, a_tch, b_tch)\n",
    "final_mse = torch.mean((f_all - Y_data) ** 2).item()\n",
    "print(f\"Final MSE on all data: {final_mse:.4f}\")\n",
    "print(f\"Learned {K} affine pieces with slopes: {a_np.flatten().round(3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}