{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Program: Circuit Sizing\n",
    "\n",
    "This notebook demonstrates how to use CVXPYlayers with **geometric programs** (GPs).\n",
    "\n",
    "Geometric programs are a class of optimization problems where the objective and constraints are formed from *posynomials* — sums of monomials with positive coefficients. CVXPY supports GPs via `cp.Variable(pos=True)` and the `gp=True` flag.\n",
    "\n",
    "**Problem**: We size transistor widths to minimize propagation delay subject to area and power budgets. This is a classic GP from Boyd et al. (2007).\n",
    "\n",
    "**Key API**:\n",
    "- `cp.Variable(pos=True)` — positive variables for GP\n",
    "- `problem.is_dgp(dpp=True)` — verify DGP-DPP compliance\n",
    "- `CvxpyLayer(..., gp=True)` — enable GP mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from cvxpylayers.torch import CvxpyLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Geometric Program\n",
    "\n",
    "We model a simple 3-stage digital circuit. Each stage $i$ has a transistor width $w_i > 0$.\n",
    "\n",
    "- **Delay** of each stage is inversely proportional to its width: $d_i = \\alpha_i / w_i$\n",
    "- **Area** of each stage is proportional to its width: total area $= \\sum_i w_i$\n",
    "- **Power** scales as width times switching frequency: total power $= \\sum_i \\beta_i w_i$\n",
    "\n",
    "The total delay is $\\sum_i d_i = \\sum_i \\alpha_i / w_i$, which we minimize subject to parametric area and power budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stages = 3\n",
    "\n",
    "# Positive variables (required for GP)\n",
    "w = cp.Variable(n_stages, pos=True, name=\"widths\")\n",
    "\n",
    "# Fixed coefficients\n",
    "alpha = np.array([1.0, 1.5, 0.8])  # delay coefficients\n",
    "beta = np.array([0.5, 0.8, 0.6])   # power coefficients\n",
    "\n",
    "# Parametric budgets\n",
    "A_max = cp.Parameter(pos=True, name=\"area_budget\")\n",
    "P_max = cp.Parameter(pos=True, name=\"power_budget\")\n",
    "\n",
    "# Objective: minimize total delay (sum of alpha_i / w_i)\n",
    "delay = sum(alpha[i] * cp.inv_pos(w[i]) for i in range(n_stages))\n",
    "objective = cp.Minimize(delay)\n",
    "\n",
    "# Constraints\n",
    "constraints = [\n",
    "    cp.sum(w) <= A_max,                        # area budget\n",
    "    beta @ w <= P_max,                          # power budget\n",
    "    w >= 0.1,                                   # minimum width\n",
    "]\n",
    "\n",
    "problem = cp.Problem(objective, constraints)\n",
    "assert problem.is_dgp(dpp=True), \"Problem must be DGP-DPP compliant\"\n",
    "print(f\"Problem is DGP: {problem.is_dgp()}, DPP: {problem.is_dgp(dpp=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CvxpyLayer with `gp=True`\n",
    "\n",
    "When `gp=True`, CVXPYlayers internally transforms the GP to an equivalent convex problem in log-space, solves it, and maps the solution back. Gradients flow through this transformation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = CvxpyLayer(problem, parameters=[A_max, P_max], variables=[w], gp=True)\n",
    "\n",
    "# Solve for specific budget values\n",
    "A_max_tch = torch.tensor(5.0, dtype=torch.float64, requires_grad=True)\n",
    "P_max_tch = torch.tensor(3.0, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "(w_opt,) = layer(A_max_tch, P_max_tch)\n",
    "print(f\"Optimal widths: {w_opt.detach().numpy().round(4)}\")\n",
    "print(f\"Total delay:    {sum(alpha / w_opt.detach().numpy()):.4f}\")\n",
    "print(f\"Total area:     {w_opt.sum().item():.4f} (budget: {A_max_tch.item()})\")\n",
    "print(f\"Total power:    {(torch.tensor(beta) @ w_opt).item():.4f} (budget: {P_max_tch.item()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis via Gradients\n",
    "\n",
    "The key advantage of differentiable optimization: we can compute how the optimal delay changes with respect to the budget parameters. This gives us *sensitivity* or *shadow price* information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradient of total delay w.r.t. budgets\n",
    "total_delay = sum(torch.tensor(alpha[i]) * (1.0 / w_opt[i]) for i in range(n_stages))\n",
    "total_delay.backward()\n",
    "\n",
    "print(f\"d(delay)/d(area_budget)  = {A_max_tch.grad.item():.6f}\")\n",
    "print(f\"d(delay)/d(power_budget) = {P_max_tch.grad.item():.6f}\")\n",
    "print()\n",
    "print(\"Negative gradients mean increasing the budget decreases delay.\")\n",
    "print(f\"A unit increase in area budget reduces delay by ~{-A_max_tch.grad.item():.4f}\")\n",
    "print(f\"A unit increase in power budget reduces delay by ~{-P_max_tch.grad.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay vs. Area Budget Tradeoff\n",
    "\n",
    "Sweep the area budget and plot how the optimal delay changes. The gradient gives the local slope of this curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_values = np.linspace(1.5, 10.0, 30)\n",
    "delays = []\n",
    "sensitivities = []\n",
    "P_fixed = torch.tensor(5.0, dtype=torch.float64)\n",
    "\n",
    "for a_val in area_values:\n",
    "    A_tch = torch.tensor(a_val, dtype=torch.float64, requires_grad=True)\n",
    "    (w_sol,) = layer(A_tch, P_fixed)\n",
    "    d = sum(torch.tensor(alpha[i]) * (1.0 / w_sol[i]) for i in range(n_stages))\n",
    "    d.backward()\n",
    "    delays.append(d.item())\n",
    "    sensitivities.append(A_tch.grad.item())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(area_values, delays, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Area Budget')\n",
    "ax1.set_ylabel('Optimal Delay')\n",
    "ax1.set_title('Delay vs. Area Budget')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(area_values, sensitivities, 'r-', linewidth=2)\n",
    "ax2.set_xlabel('Area Budget')\n",
    "ax2.set_ylabel('d(delay)/d(area_budget)')\n",
    "ax2.set_title('Sensitivity (Shadow Price)')\n",
    "ax2.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"The sensitivity approaches zero as the area budget becomes non-binding.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}